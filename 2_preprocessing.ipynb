{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featrue/target overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">X_length</th>\n",
       "      <th colspan=\"3\" halign=\"left\">X_readability</th>\n",
       "      <th colspan=\"9\" halign=\"left\">X_topic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">X_sentiment</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>flesch reading</th>\n",
       "      <th>word/sentence</th>\n",
       "      <th>syllable/word</th>\n",
       "      <th>topic1</th>\n",
       "      <th>...</th>\n",
       "      <th>topic14</th>\n",
       "      <th>n_topic</th>\n",
       "      <th>depth</th>\n",
       "      <th>depth/word</th>\n",
       "      <th>redundancy</th>\n",
       "      <th>redundancy/sentence</th>\n",
       "      <th>rank</th>\n",
       "      <th>pos topic</th>\n",
       "      <th>neg topic</th>\n",
       "      <th>density</th>\n",
       "      <th>helpful class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(X_length, sentence), (X_length, word), (X_readability, flesch reading), (X_readability, word/sentence), (X_readability, syllable/word), (X_topic, topic1), (X_topic, ...), (X_topic, topic14), (X_topic, n_topic), (X_topic, depth), (X_topic, depth/word), (X_topic, redundancy), (X_topic, redundancy/sentence), (X_topic, rank), (X_sentiment, pos topic), (X_sentiment, neg topic), (X_sentiment, density), (Y, helpful class)]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [np.array(['X_length', 'X_length', 'X_readability', 'X_readability', 'X_readability','X_topic', 'X_topic', \\\n",
    "                      'X_topic', 'X_topic', 'X_topic', 'X_topic', 'X_topic', 'X_topic', 'X_topic', 'X_sentiment', 'X_sentiment', \\\n",
    "                      'X_sentiment', 'Y']),\n",
    "    np.array(['sentence', 'word', 'flesch reading', 'word/sentence', 'syllable/word', 'topic1', '...', 'topic14', \\\n",
    "              'n_topic', 'depth', 'depth/word', 'redundancy', 'redundancy/sentence', 'rank', 'pos topic', 'neg topic', 'density', \\\n",
    "              'helpful class'])]\n",
    "df_ex = pd.DataFrame(columns=features)\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tablet = pd.read_csv('./data/review_tablet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "df_length= pd.DataFrame(columns=['sentence', 'word'])\n",
    "\n",
    "for i in range(0, 1257):\n",
    "    df_tablet['review'][i] = re.sub('(?<=\\?)(?=[a-zA-Z])', ' ', df_tablet['review'][i]) # put space after punctuation marks\n",
    "    df_tablet['review'][i] = re.sub('(?<=\\,)(?=[a-zA-Z])', ' ', df_tablet['review'][i])\n",
    "    df_tablet['review'][i] = re.sub('(?<=\\!)(?=[a-zA-Z])', ' ', df_tablet['review'][i])\n",
    "    df_tablet['review'][i] = re.sub('(?<=\\.)(?=[a-zA-Z])', ' ', df_tablet['review'][i])\n",
    "    \n",
    "    sentence = len(TextBlob(df_tablet['review'][i]).sentences) # count number of sentences\n",
    "    word = len(TextBlob(df_tablet['review'][i]).words) # count the number of words\n",
    "    df_length.loc[len(df_length)] = [sentence, word]\n",
    "\n",
    "df_tablet = pd.concat([df_tablet, df_length], axis=1) # merge with the original df\n",
    "df_tablet = df_tablet.drop(['author', 'n_help', 'n_total', 'helpful class'], axis=1) # drop unnecessary columns\n",
    "df_tablet['helpful score'] = df_tablet['helpful score'].round(2) # round off number to three decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textstat.textstat import textstat\n",
    "\n",
    "df_readability = pd.DataFrame(columns=['flesch reading', 'word/sentence', 'syllable'])\n",
    "\n",
    "for i in range(0, 1257):\n",
    "    n_word = df_tablet['word'][i] # define variables needed in following calculation\n",
    "    n_sentence = df_tablet['sentence'][i]\n",
    "    n_syllable = textstat.syllable_count(df_tablet['review'][i])\n",
    "    \n",
    "    flesch_reading = (206.835 - 1.015 * (n_word / n_sentence) - 84.6 * (n_syllable / n_word)).round(2) # flesch reading score\n",
    "    syllable = (n_syllable / n_word).round(2) # calculate average syllable per word\n",
    "    word_sentence = (n_word / n_sentence).round(2) # caldulate average word per sentence\n",
    "    \n",
    "    df_readability.loc[len(df_readability)] = [flesch_reading, word_sentence, syllable]\n",
    "\n",
    "df_tablet = pd.concat([df_tablet, df_readability], axis=1) # merge with original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tablet['flesch reading'] = df_tablet['flesch reading'].apply(lambda x: 1 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_candidate_words(text, good_tags=set(['NN','NNP','NNS','NNPS'])):\n",
    "    import itertools, nltk, string\n",
    "\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    tagged_words = itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent) # tokenize and POS-tag words\n",
    "                                                                    for sent in nltk.sent_tokenize(text)))\n",
    "    candidates = [word.lower() for word, tag in tagged_words # filter on certain POS tags and lowercase all words\n",
    "                  if tag in good_tags and word.lower() not in stop_words\n",
    "                  and not all(char in punct for char in word)]\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_candidates = []\n",
    "for i in range(0, 1257):\n",
    "    topics_candidate = (extract_candidate_words(df_tablet['review'][i])) # extract unigram noun from reviews\n",
    "    topic_candidates.append(topic_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/topic_candidates\",'wb') # save topic keywords as a pickle file for future use\n",
    "pickle.dump(topic_candidates,fileObject)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/topic_candidates\",'r') # load topic keywords \n",
    "topic_candidates = pickle.load(fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(topic_candidates).most_common(50) # extract most frequently used unigram nouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import singularize\n",
    "df_tablet['keyword'] = 0  # make new column to append text data (any value could be assigned to make column, in this case 0)\n",
    "for i in range(0, 1257):\n",
    "    texts = [singularize(word) for word in df_tablet['review'][i].split()]\n",
    "    df_tablet['keyword'][i] = texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### topic_1, topic_2, ..., topic_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ./data/topics # module that contains variables including topic keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns with topic words\n",
    "for topic_column in topics_column:\n",
    "    df_tablet[topic_column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 1257): # count occurence of each topic in each review\n",
    "    if any(word in topic_display for word in df_tablet['keyword'][i]): df_tablet['display'][i] =1 \n",
    "    if any(word in topic_sound for word in df_tablet['keyword'][i]): df_tablet['sound'][i] = 1\n",
    "    if any(word in topic_os for word in df_tablet['keyword'][i]): df_tablet['os'][i] = 1\n",
    "    if any(word in topic_security for word in df_tablet['keyword'][i]): df_tablet['security'][i] = 1\n",
    "    if any(word in topic_hardware for word in df_tablet['keyword'][i]): df_tablet['hardware'][i] = 1\n",
    "    if any(word in topic_battery for word in df_tablet['keyword'][i]): df_tablet['battery'][i] = 1\n",
    "    if any(word in topic_bug for word in df_tablet['keyword'][i]): df_tablet['bug'][i] = 1\n",
    "    if any(word in topic_price for word in df_tablet['keyword'][i]): df_tablet['price'][i] = 1\n",
    "    if any(word in topic_cs for word in df_tablet['keyword'][i]): df_tablet['cs'][i] = 1\n",
    "    if any(word in topic_wifi for word in df_tablet['keyword'][i]): df_tablet['wifi'][i] = 1\n",
    "    if any(word in topic_accesory for word in df_tablet['keyword'][i]): df_tablet['accesory'][i] = 1\n",
    "    if any(word in topic_app for word in df_tablet['keyword'][i]): df_tablet['app'][i] = 1\n",
    "    if any(word in topic_compatible for word in df_tablet['keyword'][i]): df_tablet['compatible'][i] = 1\n",
    "    if any(word in topic_usable for word in df_tablet['keyword'][i]): df_tablet['usable'][i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  #### number of topics per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tablet['total topic'] = 0\n",
    "for topic_column in topics_column:\n",
    "    df_tablet['total topic'] += df_tablet[topic_column] # total topics per review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df_depth = pd.DataFrame(columns=['depth'])\n",
    "\n",
    "for i in range(0, 1257):\n",
    "    sentences = sent_tokenize(df_tablet['review'][i])\n",
    "    depth_sentences = set()\n",
    "    for sentence in sentences:\n",
    "        for topic_list in topics_list:\n",
    "            if any(word in word_tokenize(sentence) for word in topic_list):\n",
    "                depth_sentences.add(sentence)\n",
    "    \n",
    "    depth_sentence = [len(tokenizer.tokenize(depth_sentence)) for depth_sentence in depth_sentences]\n",
    "    df_depth.loc[len(df_depth)] = [sum(depth_sentence)]\n",
    "    #print('review No', i, 'has', sum(depth_sentence), 'words realted to the topic',)\n",
    "df_tablet = pd.concat([df_tablet, df_depth], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tablet['depth/word'] = (df_tablet['depth'] / df_tablet['word']).round(2) # depth per word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "\n",
    "df_redundancy = pd.DataFrame(columns=['redundancy'])\n",
    "\n",
    "for i in range(0, 1257):\n",
    "    sentences = sent_tokenize(df_tablet['review'][i])\n",
    "    depth_sentences = set()\n",
    "    for sentence in sentences:\n",
    "        for topic_list in topics_list:\n",
    "            if any(word in word_tokenize(sentence) for word in topic_list): \n",
    "                depth_sentences.add(sentence)\n",
    "        \n",
    "    redundancy = len(sentences) - len(depth_sentences)\n",
    "    df_redundancy.loc[len(df_redundancy)] = [redundancy]\n",
    "    #print(i, len(sentences) - len(depth_sentences)) # redundancy\n",
    "df_tablet = pd.concat([df_tablet, df_redundancy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tablet['redundancy/sentence'] = (df_tablet['redundancy'] / df_tablet['sentence']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rank = pd.DataFrame(columns=['rank'])\n",
    "\n",
    "for i in range(0, 1257):\n",
    "    rank = []\n",
    "    for topic_column in topics_column:\n",
    "        rank.append(round(df_tablet[topic_column][i] * int(df_tablet[topic_column].sum())  / int(df_tablet['total topic'].sum()), 2))\n",
    "    df_rank.loc[len(df_rank)] = [sum(rank)]\n",
    "df_tablet = pd.concat([df_tablet, df_rank], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### positive/negative topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ./data/sentiment_pos_neg.py # scripts that contain how to count number of postive/negative topics in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_pos_neg() # run pre-defined function in external module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tablet= pd.concat([df_tablet,df_sentiment], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_density = pd.DataFrame(columns=['density'])\n",
    "for i in range(0, 1257):\n",
    "    if df_tablet['total topic'][i] != 0:\n",
    "        density = ((df_tablet['pos topic'][i] + df_tablet['neg topic'][i]) / df_tablet['total topic'][i]).round(2)\n",
    "    else:\n",
    "        density = 0\n",
    "    df_density.loc[len(df_density)] = [density]\n",
    "df_tablet = pd.concat([df_tablet, df_density], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Help class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign help class(0, 1) to solve as a classification problem\n",
    "df_tablet['help class'] = df_tablet['helpful score'].apply(lambda x: 1 if x >= 0.80 else 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = df_tablet.columns.tolist()\n",
    "cols = ['star', 'review', 'sentence', 'word', 'flesch reading', 'word/sentence', 'syllable', 'display', 'sound', \\\n",
    "        'os', 'security', 'hardware', 'battery', 'bug', 'price', 'cs', 'wifi', 'accesory', 'app', 'compatible', 'usable', \\\n",
    "        'total topic', 'depth', 'depth/word', 'redundancy', 'redundancy/sentence', 'rank', 'pos topic', 'neg topic', 'density', \\\n",
    "        'helpful score', 'help class']\n",
    "df_tablet = df_tablet[cols] # change the order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tablet.isnull().any() # check whether thre's a null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>flesch reading</th>\n",
       "      <th>word/sentence</th>\n",
       "      <th>syllable</th>\n",
       "      <th>display</th>\n",
       "      <th>sound</th>\n",
       "      <th>os</th>\n",
       "      <th>security</th>\n",
       "      <th>hardware</th>\n",
       "      <th>battery</th>\n",
       "      <th>bug</th>\n",
       "      <th>price</th>\n",
       "      <th>cs</th>\n",
       "      <th>wifi</th>\n",
       "      <th>accesory</th>\n",
       "      <th>app</th>\n",
       "      <th>compatible</th>\n",
       "      <th>usable</th>\n",
       "      <th>total topic</th>\n",
       "      <th>depth</th>\n",
       "      <th>depth/word</th>\n",
       "      <th>redundancy</th>\n",
       "      <th>redundancy/sentence</th>\n",
       "      <th>rank</th>\n",
       "      <th>pos topic</th>\n",
       "      <th>neg topic</th>\n",
       "      <th>density</th>\n",
       "      <th>helpful score</th>\n",
       "      <th>help class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.999204</td>\n",
       "      <td>13.498807</td>\n",
       "      <td>228.099443</td>\n",
       "      <td>77.891710</td>\n",
       "      <td>16.001933</td>\n",
       "      <td>1.334018</td>\n",
       "      <td>0.496420</td>\n",
       "      <td>0.169451</td>\n",
       "      <td>0.167064</td>\n",
       "      <td>0.077963</td>\n",
       "      <td>0.370724</td>\n",
       "      <td>0.256165</td>\n",
       "      <td>0.236277</td>\n",
       "      <td>0.392204</td>\n",
       "      <td>0.238663</td>\n",
       "      <td>0.203660</td>\n",
       "      <td>0.279236</td>\n",
       "      <td>0.368337</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.456643</td>\n",
       "      <td>3.734288</td>\n",
       "      <td>148.308671</td>\n",
       "      <td>0.594105</td>\n",
       "      <td>6.466985</td>\n",
       "      <td>0.491074</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>1.173429</td>\n",
       "      <td>0.218775</td>\n",
       "      <td>0.354789</td>\n",
       "      <td>0.709149</td>\n",
       "      <td>0.511535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.684748</td>\n",
       "      <td>17.611027</td>\n",
       "      <td>304.980365</td>\n",
       "      <td>15.362226</td>\n",
       "      <td>8.740415</td>\n",
       "      <td>0.173927</td>\n",
       "      <td>0.500186</td>\n",
       "      <td>0.375299</td>\n",
       "      <td>0.373182</td>\n",
       "      <td>0.268221</td>\n",
       "      <td>0.483191</td>\n",
       "      <td>0.436688</td>\n",
       "      <td>0.424963</td>\n",
       "      <td>0.488436</td>\n",
       "      <td>0.426436</td>\n",
       "      <td>0.402879</td>\n",
       "      <td>0.448802</td>\n",
       "      <td>0.482546</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>0.498315</td>\n",
       "      <td>2.906074</td>\n",
       "      <td>208.780723</td>\n",
       "      <td>0.275841</td>\n",
       "      <td>9.308961</td>\n",
       "      <td>0.257007</td>\n",
       "      <td>0.247442</td>\n",
       "      <td>1.333125</td>\n",
       "      <td>0.479547</td>\n",
       "      <td>0.377165</td>\n",
       "      <td>0.287818</td>\n",
       "      <td>0.500066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>71.090000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>78.310000</td>\n",
       "      <td>15.080000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>85.860000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>3045.000000</td>\n",
       "      <td>145.670000</td>\n",
       "      <td>86.670000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              star     sentence         word  flesch reading  word/sentence  \\\n",
       "count  1257.000000  1257.000000  1257.000000     1257.000000    1257.000000   \n",
       "mean      2.999204    13.498807   228.099443       77.891710      16.001933   \n",
       "std       1.684748    17.611027   304.980365       15.362226       8.740415   \n",
       "min       1.000000     1.000000     1.000000        1.000000       0.670000   \n",
       "25%       1.000000     4.000000    53.000000       71.090000      11.250000   \n",
       "50%       3.000000     8.000000   120.000000       78.310000      15.080000   \n",
       "75%       5.000000    17.000000   284.000000       85.860000      19.000000   \n",
       "max       5.000000   227.000000  3045.000000      145.670000      86.670000   \n",
       "\n",
       "          syllable      display        sound           os     security  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean      1.334018     0.496420     0.169451     0.167064     0.077963   \n",
       "std       0.173927     0.500186     0.375299     0.373182     0.268221   \n",
       "min       0.680000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.250000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.320000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.390000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       2.920000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          hardware      battery          bug        price           cs  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean      0.370724     0.256165     0.236277     0.392204     0.238663   \n",
       "std       0.483191     0.436688     0.424963     0.488436     0.426436   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              wifi     accesory          app   compatible       usable  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean      0.203660     0.279236     0.368337     0.021480     0.456643   \n",
       "std       0.402879     0.448802     0.482546     0.145035     0.498315   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       total topic        depth   depth/word   redundancy  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean      3.734288   148.308671     0.594105     6.466985   \n",
       "std       2.906074   208.780723     0.275841     9.308961   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000    29.000000     0.440000     2.000000   \n",
       "50%       3.000000    76.000000     0.640000     4.000000   \n",
       "75%       6.000000   182.000000     0.780000     8.000000   \n",
       "max      14.000000  1913.000000     1.040000   130.000000   \n",
       "\n",
       "       redundancy/sentence         rank    pos topic    neg topic  \\\n",
       "count          1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean              0.491074     0.329467     1.173429     0.218775   \n",
       "std               0.257007     0.247442     1.333125     0.479547   \n",
       "min               0.000000     0.000000     0.000000     0.000000   \n",
       "25%               0.330000     0.120000     0.000000     0.000000   \n",
       "50%               0.500000     0.300000     1.000000     0.000000   \n",
       "75%               0.640000     0.510000     2.000000     0.000000   \n",
       "max               1.000000     0.990000     7.000000     3.000000   \n",
       "\n",
       "           density  helpful score   help class  \n",
       "count  1257.000000    1257.000000  1257.000000  \n",
       "mean      0.354789       0.709149     0.511535  \n",
       "std       0.377165       0.287818     0.500066  \n",
       "min       0.000000       0.000000     0.000000  \n",
       "25%       0.000000       0.600000     0.000000  \n",
       "50%       0.290000       0.800000     1.000000  \n",
       "75%       0.500000       0.930000     1.000000  \n",
       "max       2.000000       1.000000     1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tablet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>flesch reading</th>\n",
       "      <th>word/sentence</th>\n",
       "      <th>syllable</th>\n",
       "      <th>display</th>\n",
       "      <th>sound</th>\n",
       "      <th>os</th>\n",
       "      <th>security</th>\n",
       "      <th>hardware</th>\n",
       "      <th>battery</th>\n",
       "      <th>bug</th>\n",
       "      <th>price</th>\n",
       "      <th>cs</th>\n",
       "      <th>wifi</th>\n",
       "      <th>accesory</th>\n",
       "      <th>app</th>\n",
       "      <th>compatible</th>\n",
       "      <th>usable</th>\n",
       "      <th>total topic</th>\n",
       "      <th>depth</th>\n",
       "      <th>depth/word</th>\n",
       "      <th>redundancy</th>\n",
       "      <th>redundancy/sentence</th>\n",
       "      <th>rank</th>\n",
       "      <th>pos topic</th>\n",
       "      <th>neg topic</th>\n",
       "      <th>density</th>\n",
       "      <th>helpful score</th>\n",
       "      <th>help class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1</td>\n",
       "      <td>* Micro SD Card adapter doesn't read/write pro...</td>\n",
       "      <td>13</td>\n",
       "      <td>238</td>\n",
       "      <td>79.80</td>\n",
       "      <td>18.31</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>210</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2</td>\n",
       "      <td>(The title of this review is trying to describ...</td>\n",
       "      <td>56</td>\n",
       "      <td>960</td>\n",
       "      <td>74.04</td>\n",
       "      <td>17.14</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>726</td>\n",
       "      <td>0.76</td>\n",
       "      <td>24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>5</td>\n",
       "      <td>$50.00 tablet, can not complain at all!! It do...</td>\n",
       "      <td>6</td>\n",
       "      <td>89</td>\n",
       "      <td>89.97</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      star                                             review  sentence  word  \\\n",
       "1254     1  * Micro SD Card adapter doesn't read/write pro...        13   238   \n",
       "1255     2  (The title of this review is trying to describ...        56   960   \n",
       "1256     5  $50.00 tablet, can not complain at all!! It do...         6    89   \n",
       "\n",
       "      flesch reading  word/sentence  syllable  display  sound  os  security  \\\n",
       "1254           79.80          18.31      1.28        1      0   1         0   \n",
       "1255           74.04          17.14      1.36        1      0   0         1   \n",
       "1256           89.97          14.83      1.20        1      1   0         0   \n",
       "\n",
       "      hardware  battery  bug  price  cs  wifi  accesory  app  compatible  \\\n",
       "1254         1        1    1      0   0     1         1    0           0   \n",
       "1255         1        1    1      1   1     0         1    1           0   \n",
       "1256         0        0    0      1   0     0         0    0           0   \n",
       "\n",
       "      usable  total topic  depth  depth/word  redundancy  redundancy/sentence  \\\n",
       "1254       1            8    210        0.88           3                 0.23   \n",
       "1255       1           10    726        0.76          24                 0.43   \n",
       "1256       0            3     83        0.93           1                 0.17   \n",
       "\n",
       "      rank  pos topic  neg topic  density  helpful score  help class  \n",
       "1254  0.64          1          1     0.25           0.45           0  \n",
       "1255  0.84          1          1     0.20           0.60           0  \n",
       "1256  0.29          2          0     0.67           1.00           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tablet.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "import pickle\n",
    "fileObject = open(\"./data/preprocessing\",'wb') \n",
    "pickle.dump(df_tablet,fileObject)   \n",
    "fileObject.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
